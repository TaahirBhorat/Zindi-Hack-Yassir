{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "splitting into test, validation and training sets\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pylab as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn import cluster\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn import pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn import model_selection   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import os\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "%matplotlib inline\n",
    "IN_COLLAB = False\n",
    "\n",
    "if IN_COLLAB:\n",
    "    files_directory = '/content/drive/My Drive/Zindi/'\n",
    "else:\n",
    "    files_directory = ''\n",
    "\n",
    "\n",
    "def pre_process(df):\n",
    "    # cluster lat long\n",
    "    arr = np.vstack((df[['Origin_lat', 'Origin_lon']].values,\n",
    "                        df[['Destination_lat', 'Destination_lon']].values))\n",
    "    sample_ind = np.random.permutation(len(arr))\n",
    "    kmeans =MiniBatchKMeans(n_clusters=90, batch_size=10000).fit(arr[sample_ind])\n",
    "    \n",
    "    df.loc[:, 'pickup_cluster'] = kmeans.predict(df[['Origin_lat', 'Origin_lon']])\n",
    "    df.loc[:, 'dropoff_cluster'] = kmeans.predict(df[['Destination_lat', 'Destination_lon']])\n",
    "    \n",
    "    arr = np.vstack((df[['Origin_lat', 'Origin_lon']].values,\n",
    "                        df[['Destination_lat', 'Destination_lon']].values))\n",
    "    \n",
    "    # PCA lat long\n",
    "    pca = PCA().fit(arr)\n",
    "    df['pickup_pca0'] = pca.transform(df[['Origin_lat', 'Origin_lon']])[:, 0]\n",
    "    df['pickup_pca1'] = pca.transform(df[['Origin_lat', 'Origin_lon']])[:, 1]\n",
    "    df['dropoff_pca0'] = pca.transform(df[['Destination_lat', 'Destination_lon']])[:, 0]\n",
    "    df['dropoff_pca1'] = pca.transform(df[['Destination_lat', 'Destination_lon']])[:, 1]\n",
    "    \n",
    "    StartTime = pd.to_datetime(df['Timestamp'], infer_datetime_format=True)\n",
    "    \n",
    "    df['is_peak_traffic'] = [1 if (5<i<9 or 15<i<20) else 0 for i in StartTime.dt.hour]\n",
    "    df['Day_in_week'] = StartTime.dt.dayofweek\n",
    "    df['Day_in_year'] = StartTime.dt.dayofyear\n",
    "    df['Month'] = StartTime.dt.month\n",
    "    df = df.drop('Timestamp', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_weather(trips_df, weather_df):\n",
    "    trips_df['Timestamp'] = pd.to_datetime(trips_df['Timestamp'], infer_datetime_format=True)\n",
    "    weather_df['date'] = pd.to_datetime(weather_df['date'], infer_datetime_format=True)\n",
    "    \n",
    "    trips_df['date'] = trips_df['Timestamp'].dt.date\n",
    "    weather_df['date'] = weather_df['date'].dt.date\n",
    "    \n",
    "    df = pd.merge(trips_df, weather_df, how='left', on='date').drop('date', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_training_set(trips_df):\n",
    "    # remove trips with average speed over 200\n",
    "    return trips_df[(trips_df['Trip_distance'] / 1000) / (trips_df['ETA'] / (60 * 60)) <= 200]\n",
    "\n",
    "\n",
    "def split_X_y(df):\n",
    "    return df.drop(['ETA', 'ID'], axis=1), df['ETA']\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join(files_directory, 'Train.csv'))\n",
    "submission_test_set = pd.read_csv(os.path.join(files_directory, 'Test.csv'))\n",
    "weather = pd.read_csv(os.path.join(files_directory, 'Weather.csv'))\n",
    "\n",
    "train = add_weather(train, weather)\n",
    "train = train.sort_values('Timestamp', ascending=False)\n",
    "train = clean_training_set(train)\n",
    "\n",
    "submission_test_set = add_weather(submission_test_set, weather)\n",
    "\n",
    "train = pre_process(train)\n",
    "submission_test_set = pre_process(submission_test_set)\n",
    "\n",
    "print('splitting into test, validation and training sets')\n",
    "test = train.iloc[:8000]\n",
    "train = train.iloc[8000:]\n",
    "\n",
    "val = train.iloc[:8000]\n",
    "train = train.iloc[8000:]\n",
    "\n",
    "X_train, y_train = split_X_y(train)\n",
    "X_val, y_val = split_X_y(val)\n",
    "X_test, y_test = split_X_y(test)\n",
    "\n",
    "target='ETA'\n",
    "idCol='ID'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='rmse', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['ETA'],eval_metric='rmse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "xgb1 = XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# xgb1.fit(\n",
    "#     X_train, \n",
    "#     y_train, \n",
    "#     eval_metric=\"rmse\", \n",
    "#     eval_set=[(X_train, y_train), (X_test, y_test)], \n",
    "#     verbose=True, \n",
    "#     early_stopping_rounds = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[13:42:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:42:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:42:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:42:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:42:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:43:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-985490e0cfe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpredictors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midCol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodelfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-02d9a921a09a>\u001b[0m in \u001b[0;36mmodelfit\u001b[1;34m(alg, dtrain, predictors, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#Predict training set:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdtrain_predprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#Print model report:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBRegressor' object has no attribute 'predict_proba'"
     ],
     "ename": "AttributeError",
     "evalue": "'XGBRegressor' object has no attribute 'predict_proba'",
     "output_type": "error"
    }
   ],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, idCol]]\n",
    "modelfit(xgb1, train, predictors)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'ID': submission_test_set['ID'], 'ETA': xgb1.predict(submission_test_set.drop('ID', axis=1))})\n",
    "# submission.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}